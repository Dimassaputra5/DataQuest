{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = 'https://raw.githubusercontent.com/Dimassaputra5/DataQuest/refs/heads/main/training_dataset.csv'\ndata_validation = 'https://raw.githubusercontent.com/Dimassaputra5/DataQuest/refs/heads/main/validation_set.csv'\ncc = pd.read_csv(data, \n                 encoding='utf-8',  # atau 'latin1', 'iso-8859-1', dll\n                 sep=',')\ncc_validation = pd.read_csv(data_validation, \n                 encoding='utf-8',  # atau 'latin1', 'iso-8859-1', dll\n                 sep=',')\ncc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc_validation","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc.info()\ncc_validation.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cc['status_perkawinan'].unique()\n# cc['status_perkawinan'] = cc['status_perkawinan'].map({'menikah': 1, 'lajang':2, 'cerai': 3, 'unknown': -2})\n# cc['status_perkawinan'].unique()\n# ##########################################################\n# cc_validation['status_perkawinan'] = cc_validation['status_perkawinan'].map({'menikah': 1, 'lajang':2, 'cerai': 3, 'unknown': -2})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['RasioPekerjaSukuBunga'] = cc['jumlah_pekerja']/cc['suku_bunga_euribor_3bln']\n###################################################\ncc_validation['RasioPekerjaSukuBunga'] = cc_validation['jumlah_pekerja']/cc_validation['suku_bunga_euribor_3bln']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['gagal_bayar_sebelumnya'].unique()\ncc['gagal_bayar_sebelumnya'] = cc['gagal_bayar_sebelumnya'].map({'no': 0, 'yes': 1, 'unknown': -1})\ncc['gagal_bayar_sebelumnya'].unique()\n###############################################\ncc_validation['gagal_bayar_sebelumnya'] = cc_validation['gagal_bayar_sebelumnya'].map({'no': 0, 'yes': 1, 'unknown': -1})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['pinjaman_rumah'].unique()\ncc['pinjaman_rumah'] = cc['pinjaman_rumah'].map({'no': 0, 'yes': 1, 'unknown': -1})\ncc['pinjaman_rumah'].unique()\n##############################################\ncc_validation['pinjaman_rumah'] = cc_validation['pinjaman_rumah'].map({'no': 0, 'yes': 1, 'unknown': -1})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['pinjaman_pribadi'].unique()\ncc['pinjaman_pribadi'] = cc['pinjaman_pribadi'].map({'no': 0, 'yes': 1, 'unknown': -1})\ncc['pinjaman_pribadi'].unique()\n################################################\ncc_validation['pinjaman_pribadi'] = cc_validation['pinjaman_pribadi'].map({'no': 0, 'yes': 1, 'unknown': -1})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['jenis_kontak'].unique()\ncc['jenis_kontak'] = cc['jenis_kontak'].map({'cellular': 0, 'telephone': 1})\n##########################################################\ncc_validation['jenis_kontak'] = cc_validation['jenis_kontak'].map({'cellular': 0, 'telephone': 1})\ncc['jenis_kontak'].unique() ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['bulan_kontak_terakhir'].unique()\ncc['bulan_kontak_terakhir'] = cc['bulan_kontak_terakhir'].map({\n    'jul': 7, 'nov': 11, 'may': 5, 'aug': 8, 'oct': 10, 'apr': 4, 'jun': 6, 'sep': 9, 'mar': 3, 'dec':12\n}).astype(int)\ncc['bulan_kontak_terakhir'].unique()\n#####################################################################\ncc_validation['bulan_kontak_terakhir'] = cc_validation['bulan_kontak_terakhir'].map({\n    'jul': 7, 'nov': 11, 'may': 5, 'aug': 8, 'oct': 10, 'apr': 4, 'jun': 6, 'sep': 9, 'mar': 3, 'dec':12\n}).astype(int)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['hari_kontak_terakhir'].unique()\ncc['hari_kontak_terakhir'] = cc['hari_kontak_terakhir'].map({\n    'fri': 5, 'thu': 4, 'wed': 3, 'tue': 2, 'mon': 7})\ncc['hari_kontak_terakhir'].unique()\n##############################################################\ncc_validation['hari_kontak_terakhir'] = cc_validation['hari_kontak_terakhir'].map({\n    'fri': 5, 'thu': 4, 'wed': 3, 'tue': 2, 'mon': 7})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['hasil_kampanye_sebelumnya'].unique()\ncc['hasil_kampanye_sebelumnya'] = cc['hasil_kampanye_sebelumnya'].map({\n    'nonexistent': -1, 'failure': 0, 'success': 1\n})\n###################################################################\ncc_validation['hasil_kampanye_sebelumnya'] = cc_validation['hasil_kampanye_sebelumnya'].map({\n    'nonexistent': -1, 'failure': 0, 'success': 1\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['berlangganan_deposito'] = cc['berlangganan_deposito'].astype(float)\ncc.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['total_kontak'] = cc['jumlah_kontak_kampanye_ini'] + cc['jumlah_kontak_sebelumnya']\n###################################\ncc_validation['total_kontak'] = cc_validation['jumlah_kontak_kampanye_ini'] + cc_validation['jumlah_kontak_sebelumnya']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['memiliki_pinjaman'] = cc['pinjaman_pribadi'] | cc['pinjaman_rumah']\n###################################\ncc_validation['memiliki_pinjaman'] = cc_validation['pinjaman_pribadi'] | cc_validation['pinjaman_rumah']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['rasio_ekonomi'] = cc['suku_bunga_euribor_3bln']/cc['indeks_harga_konsumen']\n####################################\ncc_validation['rasio_ekonomi'] = cc_validation['suku_bunga_euribor_3bln']/cc_validation['indeks_harga_konsumen']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['variasi_pekerjaan_terhadap_suku_bunga'] = cc['tingkat_variasi_pekerjaan']/cc['suku_bunga_euribor_3bln']\n#########################################################\ncc_validation['variasipekerjaanterhadapsukubunga'] = cc_validation['tingkat_variasi_pekerjaan']/cc_validation['suku_bunga_euribor_3bln']\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc.duplicated().sum()\ncc.drop_duplicates(inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['rasio_jumlah_pekerja_variasi_pekerjaan'] = cc['jumlah_pekerja']/cc['tingkat_variasi_pekerjaan']\n##############################################################\ncc_validation['rasio_jumlah_pekerja_variasi_pekerjaan'] = cc_validation['jumlah_pekerja']/cc_validation['tingkat_variasi_pekerjaan']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cc['rasio_kampanye_sebelumnya_jumlah_kontak_sebelumnya'] = ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cc.drop(columns=['usia'])\n# cc_validation.drop(columns=['usia'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc_num = cc.select_dtypes(include=np.number)\ncorelation_matrix = cc_num.corr()\nplt.figure(figsize=(15, 10))\nsns.heatmap(corelation_matrix, annot=True ,cmap='coolwarm') ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # First create the correlation matrix\n# correlation_matrix = cc_num.corr()\n\n# # Convert the correlation matrix to a more manageable format\n# # This will give us pairs of features and their correlation values\n# correlations = []\n# for i in range(len(correlation_matrix.columns)):\n#     for j in range(i+1, len(correlation_matrix.columns)):  # Start from i+1 to avoid duplicates\n#         col1 = correlation_matrix.columns[i]\n#         col2 = correlation_matrix.columns[j]\n#         corr_value = correlation_matrix.iloc[i, j]\n#         if abs(corr_value) < 0.2:  # Check for absolute correlation > 0.4\n#             correlations.append({\n#                 'feature1': col1,\n#                 'feature2': col2,\n#                 'correlation': corr_value\n#             })\n\n# # Sort by absolute correlation value and print\n# correlations.sort(key=lambda x: abs(x['correlation']), reverse=True)\n\n# print(\"Strong correlations (|correlation| < 0.2):\")\n# print(\"-\" * 50)\n# for corr in correlations:\n#     print(f\"{corr['feature1']} vs {corr['feature2']}: {corr['correlation']:.3f}\")\n\n# # Alternatively, if you just want the values:\n# # print(\"\\nJust correlation values < 0.2:\")\n# # print(\"-\" * 50)\n# # for corr in correlations:\n# #     print(f\"{corr['correlation']:.3f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc_validation.info()\ncc.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc['pendidikan'].unique()\ncc['pendidikan'] = cc['pendidikan'].map({'TIDAK SEKOLAH': 0, 'Tidak Tamat SD': 1, 'SD': 2, 'SMP': 3, 'SMA': 4, 'Diploma': 5, 'Pendidikan Tinggi': 6, 'unknown': -2})\n###############################################\ncc_validation['pendidikan'] = cc_validation['pendidikan'].map({'TIDAK SEKOLAH': 0, 'Tidak Tamat SD': 1, 'SD': 2, 'SMP': 3, 'SMA': 4, 'Diploma': 5, 'Pendidikan Tinggi': 6, 'unknown': -2})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc.select_dtypes(include='object').info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc = pd.get_dummies(cc, columns=['pekerjaan', 'status_perkawinan', 'pulau'], drop_first=True)\ncc.info()\ncc.head()\n################################################\ncc_validation = pd.get_dummies(cc_validation, columns=['pekerjaan', 'pulau'], drop_first=True)\ncc_validation.info()\ncc_validation.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"from cuml.ensemble import RandomForestClassifier\nfrom cuml.preprocessing import StandardScaler\nfrom cuml.model_selection import train_test_split\nfrom cuml.metrics import accuracy_score, roc_auc_score, confusion_matrix, mean_squared_error, r2_score\nfrom sklearn.model_selection import StratifiedKFold\nimport xgboost as xgb\nimport optuna\nimport cudf\nimport cupy\nimport sqlite3","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"storage_url = \"sqlite:///optuna_study2.db\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cc = cudf.DataFrame(cc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = cc.drop(columns=['berlangganan_deposito'], axis=1)\ny = cc['berlangganan_deposito']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\n\n# def objective(trial):\n#     n_estimators = trial.suggest_int('n_estimators', 5, 300)\n#     max_depth = trial.suggest_int('max_depth', 2, 40)\n#     min_samples_split = trial.suggest_int('min_samples_split', 2, 40)\n#     min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 40)\n    \n#     model = RandomForestClassifier(\n#             n_estimators=n_estimators,\n#             max_depth=max_depth,\n#             random_state=42,\n#             bootstrap=True,\n#             min_samples_split=min_samples_split,\n#             min_samples_leaf=min_samples_leaf,\n#             max_features='sqrt',\n#             n_streams=1)\n\n#     model.fit(X_train, y_train)\n\n#     y_pred = model.predict_proba(X_val).to_numpy()[:, 1]\n#     auc_score = roc_auc_score(y_val, y_pred)\n\n    \n\n#     return  auc_score\n\ndef objective(trial):\n    param = {\n        'verbosity': 0,\n        'objective': 'binary:logistic',\n        'eval_metric': 'logloss',\n        'booster': 'gbtree',\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'gamma': trial.suggest_float('gamma', 0, 5),\n        'lambda': trial.suggest_float('lambda', 0, 5),\n        'alpha': trial.suggest_float('alpha', 0, 5),\n    }\n\n    model = xgb.XGBClassifier(**param, use_label_encoder=False)\n    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n    preds = model.predict_proba(X_val)\n    auc_score = roc_auc_score(y_val, y_pred)\n    return auc_score\n\nstudy = optuna.create_study(direction='maximize', study_name='XGboost_Study',storage=storage_url, load_if_exists=True)\nstudy.optimize(objective, n_trials = 100)\n\nbest_params = study.best_params\nprint(\"best parameter\", best_params)\n\n# best_model = RandomForestClassifier(\n#             n_estimators=best_params['n_estimators'],\n#             max_depth=best_params['max_depth'],\n#             random_state=42,\n#             bootstrap=True,\n#             min_samples_split=best_params['min_samples_split'],\n#             min_samples_leaf=best_params['min_samples_leaf'],\n#             max_features='sqrt',\n#             n_streams=1)\n\n# best_model.fit(X_train, y_train)\n\nbest_model = xgb.XGBClassifier(**study.best_params, use_label_encoder=False)\nbest_model.fit(X_train, y_train)\n\ny_pred = best_model.predict_proba(X_val).to_numpy()[:, 1]\n\n\nauc_score = roc_auc_score(y_val, y_pred)\nprint(f\"AUC Score: {auc_score:.4f}\")\n\nprint(y_pred[:10]) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# X_train = cc.drop(columns=['berlangganan_deposito'], axis=1)\n# y_train = cc['berlangganan_deposito']\n# X_validation = cc_validation\n\n# X_train = cudf.DataFrame(X_train)\n# y_train = cudf.Series(y_train)\n# X_validation = cudf.DataFrame(X_validation)\n\n# scaler = StandardScaler()\n\n# X_train = scaler.fit_transform(X_train)\n# X_validation = scaler.transform(X_validation)\n\n# model = RandomForestRegressor(\n#         n_estimators=100,\n#         max_depth=6,\n#         random_state=42,\n#         bootstrap=True,\n#         min_samples_split=3,\n#         max_features='sqrt',\n#         n_streams=1)\n\n# model.fit(X_train, y_train)\n\n# y_val_pred = model.predict(X_validation)\n\n# print(y_val_pred[:10]) \n\n# submission = cudf.DataFrame({'customer_number': cc_validation['customer_number'] ,'berlangganan_deposito': y_val_pred})\n# submission.to_csv(\"Validation Result Submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}